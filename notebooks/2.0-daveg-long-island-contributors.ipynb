{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 CMTE_ID\n",
      "2 AMNDT_IND\n",
      "3 RPT_TP\n",
      "4 TRANSACTION_PGI\n",
      "5 IMAGE_NUM\n",
      "6 TRANSACTION_TP\n",
      "7 ENTITY_TP\n",
      "8 NAME\n",
      "9 CITY\n",
      "10 STATE\n",
      "11 ZIP_CODE\n",
      "12 EMPLOYER\n",
      "13 OCCUPATION\n",
      "14 TRANSACTION_DT\n",
      "15 TRANSACTION_AMT\n",
      "16 OTHER_ID\n",
      "17 TRAN_ID\n",
      "18 FILE_NUM\n",
      "19 MEMO_CD\n",
      "20 MEMO_TEXT\n",
      "21 SUB_ID\n",
      "\n"
     ]
    }
   ],
   "source": [
    "header_columns = \"\"\"CMTE_ID,AMNDT_IND,RPT_TP,TRANSACTION_PGI,IMAGE_NUM,TRANSACTION_TP,ENTITY_TP,NAME,CITY,STATE,ZIP_CODE,EMPLOYER,OCCUPATION,TRANSACTION_DT,TRANSACTION_AMT,OTHER_ID,TRAN_ID,FILE_NUM,MEMO_CD,MEMO_TEXT,SUB_ID\n",
    "\"\"\".split(\",\")\n",
    "for i, c in enumerate(header_columns):\n",
    "    print(i+1, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "li_zip_codes = gpd.read_file(\"../references/long_island_zipcodes.geojson\")\n",
    "zip_codes = li_zip_codes.postalcode.unique().tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bad Data! We have someone in there as \n",
    "- zipcode 'W11 3LN'. As it turns out, this is a postal code in England (!!!!!)\n",
    "- tranaction_dt 'LINCOLN' (!)\n",
    "- shape error, because some of the data is so badly formed that it is missing entire columns\n",
    "\n",
    "That last one is fatal to pretty much any attempt to read data. It means that we would have to do extra work, testing each record to make sure it is actually complete. \n",
    "\n",
    "the data is in not great shape, unfortunately. That's always the case with things like this. \n",
    "\n",
    "\n",
    "This scanned 18GB of data from my machine in just over a minute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STREAMING CHUNK SIZE: 2380 rows\n"
     ]
    }
   ],
   "source": [
    "fec_df = pl.scan_csv(\n",
    "    \"../data/raw/by_date/*.txt\", \n",
    "    separator='|', \n",
    "    has_header=False, \n",
    "    infer_schema_length=0,\n",
    "    ignore_errors=True,\n",
    "    missing_utf8_is_empty_string=True,\n",
    ").filter(pl.col(\"column_10\") == \"NY\").filter(pl.col(\"column_11\").str.slice(0,5).is_in(zip_codes)).collect(streaming=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a subset of the data, we can apply our header column to it so we can get the names we want to work with, which were taken from here:\n",
    "\n",
    "https://www.fec.gov/campaign-finance-data/contributions-individuals-file-description/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fec_df.columns = header_columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then write the file to parquet, which will let us use it with Pandas in our next notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fec_df.write_parquet(\"../data/processed/individual_2020_li.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df910395cc413df7aae2ff0bdd27dad0b30cac9664131e33d846155d5f5a977f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
